{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df8aaacdb85e490285e25c80cbb585f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>1</td><td>application_1589981439126_0002</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-88-178.ec2.internal:20888/proxy/application_1589981439126_0002/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-83-156.ec2.internal:8042/node/containerlogs/container_1589981439126_0002_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql.types import StringType\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words = sorted(stop_words)\n",
    "\n",
    "def extractSentence(record):\n",
    "    try:\n",
    "        split_record = record.strip().split('\\t')\n",
    "        genre = split_record[3]\n",
    "        sentences = []\n",
    "        if (len(split_record[8])>0):\n",
    "            sentences.append(split_record[8])\n",
    "        if (len(split_record[9])>0):\n",
    "            sentences.append(split_record[9])\n",
    "        if(len(sentences)>0):\n",
    "            return [(genre,sentence) for sentence in sentences]\n",
    "        else:\n",
    "            return ()\n",
    "    except:\n",
    "        return()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f290e04bba412799c9f6f73288ed60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------+\n",
      "|     genre|prediction| count|\n",
      "+----------+----------+------+\n",
      "|   fiction|         0|143591|\n",
      "|   fiction|         1|  9236|\n",
      "|   fiction|         2|  1292|\n",
      "|   fiction|         4|   577|\n",
      "|government|         0|104137|\n",
      "|government|         1| 47476|\n",
      "|government|         2|   263|\n",
      "|government|         4|  2824|\n",
      "|     slate|         0|123182|\n",
      "|     slate|         1| 29594|\n",
      "|     slate|         2|  1170|\n",
      "|     slate|         3|     3|\n",
      "|     slate|         4|   663|\n",
      "| telephone|         0|118294|\n",
      "| telephone|         1|  4150|\n",
      "| telephone|         2| 37688|\n",
      "| telephone|         3|  5958|\n",
      "| telephone|         4|   606|\n",
      "|    travel|         0|106035|\n",
      "|    travel|         1| 48194|\n",
      "|    travel|         2|    59|\n",
      "|    travel|         4|   412|\n",
      "+----------+----------+------+"
     ]
    }
   ],
   "source": [
    "train = sc.textFile('s3://comp5349-bgao6342/Assignment/train.tsv', 16)\n",
    "\n",
    "# Extract and remove the header\n",
    "header = train.first()\n",
    "data_noheader = train.filter(lambda x: x != header) \n",
    "sentence_genre = data_noheader.flatMap(extractSentence)\n",
    "\n",
    "# convert RDD to dataframe\n",
    "schema = StructType([StructField('genre', StringType(), True),\n",
    "                     StructField('sentence', StringType(), True)])\n",
    "sentence_df = sqlContext.createDataFrame(sentence_genre, schema)\n",
    "\n",
    "# TFIDF encoding \n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "\n",
    "# extract words from sentence\n",
    "regexTokenizer = RegexTokenizer(inputCol='sentence', outputCol= 'words', gaps=False, pattern=\"\\\\w+\") \n",
    "wordsData = regexTokenizer.transform(sentence_df) \n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\",numFeatures=2000)\n",
    "featurizedData = hashingTF.transform(wordsData)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)  \n",
    "feature = rescaledData.select(\"genre\", \"features\")\n",
    "\n",
    "# clustering \n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "# Trains a k-means model\n",
    "kmeans = KMeans(featuresCol=\"features\", predictionCol=\"prediction\").setK(5).setSeed(5)\n",
    "model = kmeans.fit(feature)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.transform(feature)\n",
    "prediction_genre = predictions.select(\"prediction\",\"genre\")\n",
    "prediction_count = prediction_genre.groupBy(\"genre\",\"prediction\").count().orderBy(\"genre\",\"prediction\")\n",
    "prediction_count.show(25)\n",
    "\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c551e5525844749988b510c71cd417e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('fiction', 0, 92.82), ('fiction', 1, 5.97), ('fiction', 2, 0.84), ('fiction', 4, 0.37), ('government', 0, 67.32), ('government', 1, 30.69), ('government', 2, 0.17), ('government', 4, 1.83), ('slate', 0, 79.67), ('slate', 1, 19.14), ('slate', 2, 0.76), ('slate', 3, 0.0), ('slate', 4, 0.43), ('telephone', 0, 70.96), ('telephone', 1, 2.49), ('telephone', 2, 22.61), ('telephone', 3, 3.57), ('telephone', 4, 0.36), ('travel', 0, 68.54), ('travel', 1, 31.15), ('travel', 2, 0.04), ('travel', 4, 0.27)]"
     ]
    }
   ],
   "source": [
    "# convert datagrame to a list of tuples \n",
    "prediction_list = [(row['prediction']) for row in prediction_count.collect()]\n",
    "genre_list = [(row['genre']) for row in prediction_count.collect()]\n",
    "count_list = [(row['count']) for row in prediction_count.collect()]\n",
    "genre_prediction_count = [] \n",
    "\n",
    "for i in range(len(prediction_list)):\n",
    "    temp = (genre_list[i],prediction_list[i],count_list[i])\n",
    "    genre_prediction_count.append(temp)\n",
    "\n",
    "fiction_sum= 0\n",
    "governement_sum = 0\n",
    "slate_sum = 0\n",
    "tele_sum= 0\n",
    "travel_sum= 0\n",
    "\n",
    "# calculate the percentage \n",
    "for i in range(len(genre_prediction_count)):\n",
    "    genre = genre_prediction_count[i][0]\n",
    "    count = genre_prediction_count[i][2]\n",
    "    if(genre == 'fiction'):\n",
    "        fiction_sum +=count\n",
    "    if(genre == 'government'):\n",
    "        governement_sum +=count\n",
    "    if(genre == 'slate'):\n",
    "        slate_sum +=count\n",
    "    if(genre == 'telephone'):\n",
    "        tele_sum +=count\n",
    "    if(genre == 'travel'):\n",
    "        travel_sum +=count\n",
    "\n",
    "genre_prediction_percent = []\n",
    "for i in range(len(genre_prediction_count)):\n",
    "    genre = genre_prediction_count[i][0]\n",
    "    if(genre == 'fiction'):\n",
    "        percentage = round(genre_prediction_count[i][2]/fiction_sum*100,2)\n",
    "        genre_prediction_percent.append((genre_prediction_count[i][0],genre_prediction_count[i][1],percentage))\n",
    "    if(genre == 'government'):\n",
    "        percentage = round(genre_prediction_count[i][2]/governement_sum*100,2)\n",
    "        genre_prediction_percent.append((genre_prediction_count[i][0],genre_prediction_count[i][1],percentage))\n",
    "    if(genre == 'slate'):\n",
    "        percentage = round(genre_prediction_count[i][2]/slate_sum*100,2)\n",
    "        genre_prediction_percent.append((genre_prediction_count[i][0],genre_prediction_count[i][1],percentage))\n",
    "    if(genre == 'telephone'):\n",
    "        percentage = round(genre_prediction_count[i][2]/tele_sum*100,2)\n",
    "        genre_prediction_percent.append((genre_prediction_count[i][0],genre_prediction_count[i][1],percentage))\n",
    "    if(genre == 'travel'):\n",
    "        percentage = round(genre_prediction_count[i][2]/travel_sum*100,2)\n",
    "        genre_prediction_percent.append((genre_prediction_count[i][0],genre_prediction_count[i][1],percentage))\n",
    "    \n",
    "print(genre_prediction_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
